{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ff19f1-3bd0-4a0f-9760-39f460938e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4af68c-9062-467a-927c-b05b9a36241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "#standard imports\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Sequence, Tuple\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# current working directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d513df3a-6033-45f3-8f37-2edc5c20e967",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup & Helpers (merged explicit + generic adjuncts)\n",
    "\n",
    "# -------------------- Age → bucket (PII-safe) --------------------\n",
    "def bucket_age(age: Optional[object]) -> Optional[str]:\n",
    "    try:\n",
    "        if age is None or str(age).strip() == \"\":\n",
    "            return None\n",
    "        return \"pediatric\" if int(float(age)) < 18 else \"adult\"\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _lc(s: Optional[str]) -> str:\n",
    "    return \"\" if s is None else str(s).strip().lower()\n",
    "\n",
    "# Status / subtype / base TB tokens\n",
    "RE_STB = re.compile(r\"\\bstb\\b|\\bsecondary\\b\", re.I) # secondary tuberculosis\n",
    "RE_ATB = re.compile(r\"\\batb\\b|\\bactive\\s+tb\\b|\\bactive\\b\", re.I) # active tuberculosis\n",
    "RE_NATB = re.compile(r\"\\bnatb\\b|\\binactive\\s+tb\\b|\\binactive\\b\", re.I) # inactive tuberculosis\n",
    "RE_TB_TOKEN = re.compile(r\"\\btb\\b|\\bptb\\b|\\btuberculosis\\b\", re.I) #other TB tokens\n",
    "\n",
    "# Location patterns\n",
    "# Bilateral / side-only\n",
    "RE_BILAT_PTB = re.compile(r\"\\bbilateral\\s+ptb\\b|\\bbilateral\\b.*\\bptb\\b|\\bptb\\b.*\\bbilateral\\b\", re.I)\n",
    "RE_RIGHT_PTB = re.compile(r\"\\bright\\s+ptb\\b\", re.I)\n",
    "RE_LEFT_PTB = re.compile(r\"\\bleft\\s+ptb\\b\", re.I)\n",
    "\n",
    "# Bilateral upper fields\n",
    "RE_BILAT_UPPER_FIELDS = re.compile(\n",
    "    r\"\\b(ptb\\s+in\\s+the\\s+bilateral\\s+upper\\s+field(s)?|upper\\s+fields?\\s+bilaterally|bilateral\\s+upper\\s+field(s)?)\\b\", re.I\n",
    ")\n",
    "\n",
    "# Side + “upper and middle fields”\n",
    "RE_SIDE_UPPER_MIDDLE = re.compile(r\"\\b(left|right)\\s+.*?\\bupper\\s+and\\s+middle\\s+field(s)?\\b\", re.I)\n",
    "\n",
    "# Side + single lobe (upper) via “ptb in the right upper field/zone/lobe”\n",
    "RE_RIGHT_UPPER_PTB = re.compile(r\"\\bright\\s+upper\\s+ptb\\b|\\bptb\\s+in\\s+the\\s+right\\s+upper\\s+(field|zone|lobe)\\b\", re.I)\n",
    "RE_LEFT_UPPER_PTB  = re.compile(r\"\\bleft\\s+upper\\s+ptb\\b|\\bptb\\s+in\\s+the\\s+left\\s+upper\\s+(field|zone|lobe)\\b\", re.I)\n",
    "\n",
    "# Generic “<side> <level> field/zone/lobe”\n",
    "RE_SIDE = r\"(left|right)\"\n",
    "RE_LEVEL = r\"(upper|middle|lower)\"\n",
    "RE_FIELDLOB = re.compile(rf\"\\b{RE_SIDE}\\s+{RE_LEVEL}\\s+(field|zone|lobe)\\b\", re.I)\n",
    "\n",
    "# Middle–lower fields (optionally side-aware)\n",
    "RE_MIDDLE_LOWER_FIELDS = re.compile(r\"\\bmiddle\\s+lower\\s+field(s)?\\b\", re.I)\n",
    "\n",
    "# Explicit extras (adjuncts) lexicon\n",
    "# Pleurisy / pleuritis\n",
    "RE_PLEURISY = re.compile(r\"\\bpleuritis\\b|\\bpleurisy\\b\", re.I)\n",
    "\n",
    "# Pleural effusion\n",
    "RE_PLEURAL_EFFUSION_SIDE = re.compile(r\"\\b(left|right)\\s+pleural\\s+effusion\\b\", re.I)\n",
    "RE_PLEURAL_EFFUSION_ANY = re.compile(r\"\\bpleural\\s+effusion\\b\", re.I)\n",
    "\n",
    "# Pleural thickening\n",
    "RE_PLEURAL_THICKENING_LOBE = re.compile(\n",
    "    r\"\\bpleural\\s+thickening\\s+in\\s+(left|right)\\s+(upper|middle|lower)\\s+(lobe|field|zone)\\b\", re.I\n",
    ")\n",
    "RE_PLEURAL_THICKENING_SIDE = re.compile(r\"\\b(left|right)\\s+pleural\\s+thickening\\b\", re.I)\n",
    "RE_PLEURAL_THICKENING_ANY = re.compile(r\"\\bpleural\\s+thickening\\b\", re.I)\n",
    "\n",
    "# Pleural adhesions\n",
    "RE_PLEURAL_ADH_LOBE = re.compile(\n",
    "    r\"\\bpleural\\s+adhesions?\\s+in\\s+(left|right)\\s+(upper|middle|lower)\\s+(lobe|field|zone)\\b\", re.I\n",
    ")\n",
    "RE_PLEURAL_ADH_ANY = re.compile(r\"\\bpleural\\s+adhesions?\\b\", re.I)\n",
    "\n",
    "# Decortication\n",
    "RE_DECORTICATION = re.compile(\n",
    "    r\"\\b(left|right)\\s+pleural\\s+change\\s+after\\s+decortication\\b|\\bpleural\\s+change\\s+after\\s+decortication\\b\", re.I\n",
    ")\n",
    "\n",
    "# Parenchymal patterns\n",
    "RE_FIBROUS_MAINLY = re.compile(r\"\\bmainly\\s+(fibrous)\\s+lesions\\b\", re.I)\n",
    "RE_FIBROUS_ANY = re.compile(r\"\\bfibrous\\b|\\bfibrotic\\b|\\bfibrosis\\b\", re.I)\n",
    "RE_HYPERPL_MAINLY = re.compile(r\"\\bmainly\\s+(hyperplastic)\\s+lesions\\b\", re.I)\n",
    "RE_HYPERPL_ANY = re.compile(r\"\\bhyperplastic\\b|\\bhyperplasia\\b\", re.I)\n",
    "\n",
    "# Cavitation\n",
    "RE_CAVITY_LOBE = re.compile(\n",
    "    r\"\\b(cavity\\s+formation|large\\s+cavity|cavity)\\s+in\\s+(left|right)\\s+(upper|middle|lower)\\s+(lobe|field|zone)\\b\", re.I\n",
    ")\n",
    "RE_CAVITY_ANY = re.compile(r\"\\bcav(itary|ity)\\b|\\bcavity\\s+formation\\b|\\blarge\\s+cavity\\b\", re.I)\n",
    "\n",
    "# Generic adjuncts\n",
    "ADJUNCTS_ORDER: Sequence[str] = (\n",
    "    # patterns\n",
    "    \"infiltrative\", \"nodular\", \"consolidation\", \"granulomas\", \"scarring\", \"calcifications\",\n",
    "    # pleural/airway\n",
    "    \"left pleural effusion\", \"right pleural effusion\", \"pleural effusion\",\n",
    "    \"pleural thickening\", \"pleural adhesions\", \"pneumothorax\", \"atelectasis\", \"volume loss\", \"tracheal deviation\",\n",
    "    # course\n",
    "    \"relapsed\", \"on treatment\", \"improving\", \"worsening\",\n",
    "    # microbiology\n",
    "    \"AFB positive\", \"AFB negative\", \"culture positive\", \"RNA probe positive\",\n",
    "    # comorbid\n",
    "    \"COPD\", \"emphysema\", \"scoliosis\", \"CHF\",\n",
    "    # caveat\n",
    "    \"uncertain etiology\",\n",
    ")\n",
    "\n",
    "ADJUNCTS_PAT: Dict[str, re.Pattern] = {\n",
    "    # patterns\n",
    "    \"infiltrative\": re.compile(r\"\\binfiltrat(e|es|ion|ory)\\b\", re.I),\n",
    "    \"nodular\": re.compile(r\"\\bnodul(ar|es?)\\b\", re.I),\n",
    "    \"consolidation\": re.compile(r\"\\bconsolidat(e|ion|ed)\\b\", re.I),\n",
    "    \"granulomas\": re.compile(r\"\\bgranuloma(s)?\\b\", re.I),\n",
    "    \"scarring\": re.compile(r\"\\bscarr?ing\\b\", re.I),\n",
    "    \"calcifications\": re.compile(r\"\\bcalcif(ication|ications|ied)\\b\", re.I),\n",
    "    # pleural/airway\n",
    "    \"left pleural effusion\": re.compile(r\"\\bleft pleural effusion\\b\", re.I),\n",
    "    \"right pleural effusion\": re.compile(r\"\\bright pleural effusion\\b\", re.I),\n",
    "    \"pleural effusion\": re.compile(r\"\\bpleural effusion\\b\", re.I),\n",
    "    \"pleural thickening\": re.compile(r\"\\bpleural thickening\\b|\\bpleural change(s)?\\b\", re.I),\n",
    "    \"pleural adhesions\": re.compile(r\"\\bpleural adhesions?\\b|\\bdecortication\\b\", re.I),\n",
    "    \"pneumothorax\": re.compile(r\"\\bpneumothorax\\b\", re.I),\n",
    "    \"atelectasis\": re.compile(r\"\\batelectasis\\b\", re.I),\n",
    "    \"volume loss\": re.compile(r\"\\bvolume loss\\b\", re.I),\n",
    "    \"tracheal deviation\": re.compile(r\"\\btracheal deviation\\b\", re.I),\n",
    "    # course\n",
    "    \"relapsed\": re.compile(r\"\\brelaps(e|ed|ing)\\b\", re.I),\n",
    "    \"on treatment\": re.compile(r\"\\bon (hrz?e?|antitubercular|treatment)\\b\", re.I),\n",
    "    \"improving\": re.compile(r\"\\bimprov(ing|ement)\\b\", re.I),\n",
    "    \"worsening\": re.compile(r\"\\bworsen(ing|ed)\\b\", re.I),\n",
    "    # microbiology\n",
    "    \"AFB positive\": re.compile(r\"\\bafb (smears? )?pos(itive)?\\b\", re.I),\n",
    "    \"AFB negative\": re.compile(r\"\\bafb (smears? )?neg(ative)?\\b\", re.I),\n",
    "    \"culture positive\": re.compile(r\"\\bculture positive\\b\", re.I),\n",
    "    \"RNA probe positive\": re.compile(r\"\\brna probes? pos(itive)?\\b\", re.I),\n",
    "    # comorbid\n",
    "    \"COPD\": re.compile(r\"\\bcopd\\b\", re.I),\n",
    "    \"emphysema\": re.compile(r\"\\bemphysema\\b\", re.I),\n",
    "    \"scoliosis\": re.compile(r\"\\bscoliosis\\b\", re.I),\n",
    "    \"CHF\": re.compile(r\"\\bchf\\b\", re.I),\n",
    "    # caveat\n",
    "    \"uncertain etiology\": re.compile(r\"\\bntm\\b.*\\bnot\\b.*\\bmtb\\b\", re.I),\n",
    "}\n",
    "\n",
    "# otherl helpers\n",
    "def _mk_age_prefix(age: Optional[object]) -> str:\n",
    "    bucket = bucket_age(age)\n",
    "    return f\"This {bucket} chest radiograph\" if bucket else \"This chest radiograph\"\n",
    "\n",
    "def _dedupe(seq: List[str]) -> List[str]:\n",
    "    seen, out = set(), []\n",
    "    for x in seq:\n",
    "        if x and x not in seen:\n",
    "            out.append(x); seen.add(x)\n",
    "    return out\n",
    "\n",
    "def _join_extras(extras: List[str]) -> str:\n",
    "    extras = _dedupe(extras)\n",
    "    return \"\" if not extras else \"with \" + \", \".join(extras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8009fcb0-9c71-454f-b3ec-2bc500d7fe4e",
   "metadata": {},
   "source": [
    "#### Generator (CSV/DataFrame → <stem>.txt + augmented + low-confidence)\n",
    "\n",
    "Implements the shorthand mappings (stb, atb, natb, tb, ptb, pleuritis/pleurisy…).\n",
    "\n",
    "Normalizes fields/zones → lobes and supports special cases (bilateral upper fields, side + upper&middle).\n",
    "\n",
    "Emits PII-safe sentences (adult/pediatric only).\n",
    "\n",
    "Sets low_confidence = false for TB if any status/subtype/location/extras or even a bare “tb/ptb” token is present; only rows with truly empty/no-report notes are flagged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9361d5c6-44ca-43e2-bf56-80d194bc6c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "\n",
    "#Location resolution\n",
    "def _resolve_location(note_lc: str) -> str:\n",
    "    # Special: bilateral upper fields\n",
    "    if RE_BILAT_UPPER_FIELDS.search(note_lc):\n",
    "        return \"on both upper lung lobes\"\n",
    "\n",
    "    # Special: side + \"upper and middle fields\"\n",
    "    m_um = RE_SIDE_UPPER_MIDDLE.search(note_lc)\n",
    "    if m_um:\n",
    "        side = m_um.group(1).lower()\n",
    "        return f\"on the {side} lung in the upper and middle lobes\"\n",
    "\n",
    "    # Right/Left upper lobe specific\n",
    "    if RE_RIGHT_UPPER_PTB.search(note_lc):\n",
    "        return \"in the right upper lobe\"\n",
    "    if RE_LEFT_UPPER_PTB.search(note_lc):\n",
    "        return \"in the left upper lobe\"\n",
    "\n",
    "    # Bilateral ptb\n",
    "    if RE_BILAT_PTB.search(note_lc):\n",
    "        return \"on both lungs\"\n",
    "\n",
    "    # Right/Left ptb\n",
    "    if RE_RIGHT_PTB.search(note_lc):\n",
    "        return \"on the right lung\"\n",
    "    if RE_LEFT_PTB.search(note_lc):\n",
    "        return \"on the left lung\"\n",
    "\n",
    "    # Middle lower fields (optionally side-aware if side is nearby)\n",
    "    if RE_MIDDLE_LOWER_FIELDS.search(note_lc):\n",
    "        # try to find a side within a short window\n",
    "        side_near = re.search(r\"(left|right).{0,20}middle\\s+lower\\s+field\", note_lc, re.I)\n",
    "        if side_near:\n",
    "            return f\"in the {side_near.group(1).lower()} lung in the middle and lower lobes\"\n",
    "        return \"in the middle and lower lobes\"\n",
    "\n",
    "    # Fallback: any explicit \"<side> <level> field/zone/lobe\" → \"in the <side> <level> lobe\"\n",
    "    m_lobe = RE_FIELDLOB.search(note_lc)\n",
    "    if m_lobe:\n",
    "        side, level = m_lobe.group(1).lower(), m_lobe.group(2).lower()\n",
    "        return f\"in the {side} {level} lobe\"\n",
    "    return \"\"  # unknown\n",
    "\n",
    "# Status / subtype\n",
    "def _resolve_status(note_lc: str) -> str:\n",
    "    # precedence: inactive+treated → inactive post-treatment; else active; else inactive; else none\n",
    "    inactive = bool(RE_NATB.search(note_lc))\n",
    "    active = bool(RE_ATB.search(note_lc))\n",
    "    treated = bool(re.search(r\"\\btreated\\b|\\bpost[- ]treat(ed|ment)\\b\", note_lc))\n",
    "    if inactive and treated:\n",
    "        return \"inactive post-treatment \"\n",
    "    if active:\n",
    "        return \"active \"\n",
    "    if inactive:\n",
    "        return \"inactive \"\n",
    "    return \"\"\n",
    "\n",
    "def _resolve_subtype(note_lc: str) -> str:\n",
    "    return \"secondary \" if RE_STB.search(note_lc) else \"\"\n",
    "\n",
    "# Extras\n",
    "def _resolve_extras(note_lc: str) -> List[str]:\n",
    "    extras: List[str] = []\n",
    "\n",
    "    # pleurisy (side-aware if present as \"left pleurisy\")\n",
    "    if RE_PLEURISY.search(note_lc):\n",
    "        m_side = re.search(r\"\\b(left|right)\\s+pleur(?:isy|itis)\\b\", note_lc)\n",
    "        extras.append(f\"{m_side.group(1).lower()} pleurisy\" if m_side else \"pleurisy\")\n",
    "\n",
    "    # pleural effusion (side-aware preferred)\n",
    "    m_eff_side = RE_PLEURAL_EFFUSION_SIDE.search(note_lc)\n",
    "    if m_eff_side:\n",
    "        extras.append(f\"{m_eff_side.group(1).lower()} pleural effusion\")\n",
    "    elif RE_PLEURAL_EFFUSION_ANY.search(note_lc):\n",
    "        extras.append(\"pleural effusion\")\n",
    "\n",
    "    # pleural thickening\n",
    "    m_th_lobe = RE_PLEURAL_THICKENING_LOBE.search(note_lc)\n",
    "    if m_th_lobe:\n",
    "        extras.append(f\"pleural thickening in the {m_th_lobe.group(1).lower()} {m_th_lobe.group(2).lower()} lobe\")\n",
    "    else:\n",
    "        m_th_side = RE_PLEURAL_THICKENING_SIDE.search(note_lc)\n",
    "        if m_th_side:\n",
    "            extras.append(f\"{m_th_side.group(1).lower()} pleural thickening\")\n",
    "        elif RE_PLEURAL_THICKENING_ANY.search(note_lc):\n",
    "            extras.append(\"pleural thickening\")\n",
    "\n",
    "    # pleural adhesions\n",
    "    m_adh_lobe = RE_PLEURAL_ADH_LOBE.search(note_lc)\n",
    "    if m_adh_lobe:\n",
    "        # note: your examples omit \"the\" here\n",
    "        extras.append(f\"pleural adhesions in {m_adh_lobe.group(1).lower()} {m_adh_lobe.group(2).lower()} lobe\")\n",
    "    elif RE_PLEURAL_ADH_ANY.search(note_lc):\n",
    "        extras.append(\"pleural adhesions\")\n",
    "\n",
    "    # decortication wording\n",
    "    m_dec = RE_DECORTICATION.search(note_lc)\n",
    "    if m_dec:\n",
    "        side = m_dec.group(1).lower() if m_dec.group(1) else None\n",
    "        extras.append(f\"{side} pleural change after decortication\" if side else \"pleural change after decortication\")\n",
    "\n",
    "    # fibrous / hyperplastic (respect \"mainly ... lesions\")\n",
    "    m_fm = RE_FIBROUS_MAINLY.search(note_lc)\n",
    "    if m_fm:\n",
    "        extras.append(\"mainly as fibrous lesions\")\n",
    "    elif RE_FIBROUS_ANY.search(note_lc):\n",
    "        extras.append(\"fibrous changes\")\n",
    "\n",
    "    m_hm = RE_HYPERPL_MAINLY.search(note_lc)\n",
    "    if m_hm:\n",
    "        extras.append(\"mainly as hyperplastic lesions\")\n",
    "    elif RE_HYPERPL_ANY.search(note_lc):\n",
    "        extras.append(\"hyperplastic changes\")  # if \"mainly ...\" not used\n",
    "\n",
    "    # cavity formation (prefer lobe-aware)\n",
    "    m_cav_lobe = RE_CAVITY_LOBE.search(note_lc)\n",
    "    if m_cav_lobe:\n",
    "        side, level = m_cav_lobe.group(2).lower(), m_cav_lobe.group(3).lower()\n",
    "        extras.append(f\"cavity formation in the {side} {level} lobe\")\n",
    "    elif RE_CAVITY_ANY.search(note_lc):\n",
    "        # no lobe; keep generic\n",
    "        extras.append(\"cavity formation\")\n",
    "    return _dedupe(extras)\n",
    "\n",
    "# TB sentence renderer\n",
    "def render_tb_sentence(note: Optional[str], age: Optional[object]) -> Tuple[str, Dict[str, str], Dict[str, str], List[str], bool]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      sentence,\n",
    "      status_map={'status': ...},\n",
    "      meta_map={'subtype': 'secondary' or '', 'distribution': 'both|left|right|'},\n",
    "      extras_list (for CSV),\n",
    "      low_conf (revised to only flag truly empty notes)\n",
    "    \"\"\"\n",
    "    note_lc = _lc(note)\n",
    "\n",
    "    # Status/subtype\n",
    "    status = _resolve_status(note_lc)  # e.g., \"active \", \"inactive post-treatment \", \"\"\n",
    "    subtype = _resolve_subtype(note_lc) # \"secondary \" or \"\"\n",
    "\n",
    "    # Location (no lobe abbreviations in final phrasing)\n",
    "    location = _resolve_location(note_lc)\n",
    "\n",
    "    # Extras\n",
    "    extras = _resolve_extras(note_lc)\n",
    "\n",
    "    # Build base\n",
    "    base = f\"{_mk_age_prefix(age)}, shows {status}{subtype}tuberculosis\".replace(\"  \", \" \")\n",
    "\n",
    "    # Build tail (location + extras)\n",
    "    tail_parts = []\n",
    "    if location:\n",
    "        tail_parts.append(location)\n",
    "    if extras:\n",
    "        tail_parts.append(\"with \" + \", \".join(extras))\n",
    "\n",
    "    sentence = base if not tail_parts else base + \" \" + \" \".join(tail_parts)\n",
    "    if not sentence.endswith(\".\"):\n",
    "        sentence += \".\"\n",
    "\n",
    "    # Distribution tag for CSV (coarse)\n",
    "    distribution = \"\"\n",
    "    if \"both lungs\" in location or \"both upper lung lobes\" in location:\n",
    "        distribution = \"both\"\n",
    "    elif \"on the left lung\" in location or \"in the left \" in location:\n",
    "        distribution = \"left\"\n",
    "    elif \"on the right lung\" in location or \"in the right \" in location:\n",
    "        distribution = \"right\"\n",
    "\n",
    "    # Low-confidence policy (relaxed): flag only when no usable info AND note empty/no-report\n",
    "    has_any_semantics = bool(status.strip() or subtype.strip() or location or extras or RE_TB_TOKEN.search(note_lc))\n",
    "    low_conf = not has_any_semantics and (note_lc == \"\" or \"no report\" in note_lc)\n",
    "\n",
    "    status_map = {\n",
    "        \"status\": \"active\" if status.startswith(\"active\")\n",
    "                  else (\"inactive post-treatment\" if status.startswith(\"inactive post-treatment\")\n",
    "                        else (\"inactive\" if status.startswith(\"inactive\") else \"\")),\n",
    "    }\n",
    "    meta_map = {\n",
    "        \"subtype\": \"secondary\" if subtype.strip() else \"\",\n",
    "        \"distribution\": distribution,\n",
    "    }\n",
    "    # we no longer expose lobes explicitly (text is human-readable); extras_list for CSV auditing\n",
    "    return sentence, status_map, meta_map, extras, low_conf\n",
    "\n",
    "# Normal sentence\n",
    "def render_normal_sentence(age: Optional[object]) -> str:\n",
    "    s = f\"{_mk_age_prefix(age)}, shows normal lungs\"\n",
    "    return s + \".\" if not s.endswith(\".\") else s\n",
    "\n",
    "# ---- Main generator: DataFrame -> files + augmented/low_conf DFs ----\n",
    "def generate_reports_jupyter(df: pd.DataFrame,\n",
    "                             reports_dir: Path,\n",
    "                             filename_col: str = \"Filename\",\n",
    "                             class_col: str = \"Class\",\n",
    "                             notes_col: str = \"Clinical_Notes\",\n",
    "                             age_col: str = \"Age\") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    reports_dir.mkdir(parents=True, exist_ok=True)\n",
    "    rows_all: List[Dict[str, object]] = []\n",
    "    rows_low: List[Dict[str, object]] = []\n",
    "\n",
    "    for _, r in df.iterrows():\n",
    "        fn = str(r[filename_col])\n",
    "        cls = str(r[class_col]).strip().lower()\n",
    "        note = None if pd.isna(r.get(notes_col, None)) else str(r.get(notes_col, \"\"))\n",
    "        age = r.get(age_col, None)\n",
    "\n",
    "        stem = Path(fn).stem\n",
    "        out_txt = reports_dir / f\"{stem}.txt\"\n",
    "\n",
    "        if cls == \"normal\":\n",
    "            sent = render_normal_sentence(age)\n",
    "            status_map = {\"status\": \"\"}\n",
    "            meta_map = {\"subtype\": \"\", \"distribution\": \"\"}\n",
    "            extras = []\n",
    "            low_conf = False\n",
    "        else:\n",
    "            sent, status_map, meta_map, extras, low_conf = render_tb_sentence(note, age)\n",
    "\n",
    "        # write file\n",
    "        with open(out_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(sent + (\"\\n\" if not sent.endswith(\"\\n\") else \"\"))\n",
    "\n",
    "        row = {\n",
    "            \"Filename\": fn,\n",
    "            \"Class\": r[class_col],\n",
    "            \"Clinical_Notes\": note if note is not None else \"\",\n",
    "            \"Age\": \"\" if age is None or str(age).strip()==\"\" else int(float(age)),\n",
    "            \"status\": status_map[\"status\"],\n",
    "            \"subtype\": meta_map[\"subtype\"],\n",
    "            \"distribution\": meta_map[\"distribution\"],\n",
    "            \"extras\": \"; \".join(extras),\n",
    "            \"synthetic_report\": sent,\n",
    "            \"low_confidence\": \"true\" if low_conf else \"false\",\n",
    "        }\n",
    "        rows_all.append(row)\n",
    "        if low_conf:\n",
    "            rows_low.append(row)\n",
    "\n",
    "    augmented_df = pd.DataFrame(rows_all)\n",
    "    low_conf_df = pd.DataFrame(rows_low)\n",
    "    return augmented_df, low_conf_df\n",
    "\n",
    "#Run\n",
    "df = pd.read_csv(\"/gpfs/gsfs12/users/rajaramans2/projects/omsakthi_multimodal/multimodal_shenzhen/shen_demo.csv\")\n",
    "reports_dir = Path(\"/gpfs/gsfs12/users/rajaramans2/projects/omsakthi_multimodal/multimodal_shenzhen/dataset/reports\")\n",
    "augmented_df, low_conf_df = generate_reports_jupyter(df, reports_dir)\n",
    "augmented_df.to_csv(\"/augmented_reports.csv\", index=False)\n",
    "low_conf_df.to_csv(\"/low_confidence.csv\", index=False)\n",
    "display(augmented_df.head()); display(low_conf_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a195949-b6d0-4673-9d78-c73ef3ea32af",
   "metadata": {},
   "source": [
    "#### Validator (ensures structure + naming; flags PII leakage patterns)\n",
    "\n",
    "The validator checks that:\n",
    "\n",
    "1. A text file exists for every row as <stem>.txt.\n",
    "\n",
    "2. Sentence starts with “This … chest radiograph”.\n",
    "\n",
    "3. Normal rows contain “shows normal lungs”.\n",
    "\n",
    "4. TB rows contain “shows … tuberculosis”.\n",
    "\n",
    "5. Flags common punctuation issues and digits .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f875baf3-96cd-4f13-b594-37438b616608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validator\n",
    "\n",
    "def validate_reports(augmented_df: pd.DataFrame,\n",
    "                             reports_dir: Path,\n",
    "                             filename_col: str = \"Filename\",\n",
    "                             class_col: str = \"Class\",\n",
    "                             check_digits: bool = True) -> List[str]:\n",
    "    issues: List[str] = []\n",
    "\n",
    "    for _, r in augmented_df.iterrows():\n",
    "        fn = str(r[filename_col])\n",
    "        cls = str(r[class_col]).strip().lower()\n",
    "        p = reports_dir / f\"{Path(fn).stem}.txt\"\n",
    "\n",
    "        if not p.exists():\n",
    "            issues.append(f\"Missing report file: {p}\")\n",
    "            continue\n",
    "\n",
    "        txt = p.read_text(encoding=\"utf-8\").strip()\n",
    "\n",
    "        # structure\n",
    "        if not txt.startswith(\"This\"):\n",
    "            issues.append(f\"Bad prefix: {p} -> {txt}\")\n",
    "        if \"chest radiograph\" not in txt:\n",
    "            issues.append(f\"Missing 'chest radiograph': {p} -> {txt}\")\n",
    "\n",
    "        # class-specific\n",
    "        if cls == \"normal\":\n",
    "            if \"shows normal lungs\" not in txt:\n",
    "                issues.append(f\"Normal template mismatch: {p} -> {txt}\")\n",
    "        else:\n",
    "            if \"shows\" not in txt or \"tuberculosis\" not in txt:\n",
    "                issues.append(f\"TB template mismatch: {p} -> {txt}\")\n",
    "\n",
    "        # punctuation / spacing\n",
    "        if not txt.endswith(\".\"):\n",
    "            issues.append(f\"Missing trailing period: {p} -> {txt}\")\n",
    "        if \"  \" in txt:\n",
    "            issues.append(f\"Double space: {p} -> {txt}\")\n",
    "        if re.search(r\",[^\\s]\", txt):\n",
    "            issues.append(f\"Comma not followed by space: {p} -> {txt}\")\n",
    "\n",
    "        # optional PII sanity: flag digits (ages) if accidentally leaked\n",
    "        if check_digits and re.search(r\"\\d\", txt):\n",
    "            issues.append(f\"Digits present (PII risk) in: {p} -> {txt}\")\n",
    "\n",
    "    return issues\n",
    "\n",
    "# Run\n",
    "issues = validate_reports(augmented_df, Path(\"/reports\"))\n",
    "if issues:\n",
    "    print(\"VALIDATION ISSUES:\")\n",
    "    for s in issues: print(\" -\", s)\n",
    "else:\n",
    "    print(\"All reports validated cleanly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed538eee-f697-4361-9d4a-46893387b332",
   "metadata": {},
   "source": [
    "#### Generator for writing raw clinical notes to (CSV/DataFrame → <stem>.txt)\n",
    "\n",
    "1. Reads shen_demo.csv (Shenzhen Metadata file from path),\n",
    "\n",
    "2. Creates reports_default/,\n",
    "\n",
    "3. writes one .txt per image stem (e.g., CHNCXR_0483_1.txt) containing the exact Clinical_Notes value (verbatim),\n",
    "\n",
    "4. Guards against missing columns and duplicate filenames,\n",
    "\n",
    "5. Prints a concise summary.\n",
    "\n",
    "##### Behavior details\n",
    "\n",
    "1. For CHNCXR_0001_0.png (0: normal class index) → CHNCXR_0001_0.txt, contents will be normal\\n.\n",
    "\n",
    "2. For CHNCXR_0483_1.png (1: TB class index) → CHNCXR_0483_1.txt, contents will be ptb in the bilateral upper fields, left pleurisy\\n. (verbatim)\n",
    "\n",
    "3. If Clinical_Notes is missing/NaN, an empty file is written (newline only), matching “write the value under the corresponding Clinical_Notes” literally.\n",
    "\n",
    "4. Set OVERWRITE=False if preserving existing files; the code will then report how many were skipped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2b6621-415b-4fa3-8d6b-922dc4f58209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "SOURCE_CSV   = Path(\"/shen_demo.csv\")\n",
    "OUT_ROOT     = Path(\"/dataset\")\n",
    "OUT_DIR      = OUT_ROOT / \"reports_default\" # will be created if not present\n",
    "OVERWRITE    = True # set False to skip writing files that already exist\n",
    "\n",
    "# Helpers\n",
    "def _read_metadata(csv_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read shen_demo.csv and return a DataFrame with at least ['Filename', 'Clinical_Notes'].\n",
    "    We preserve Clinical_Notes verbatim; filenames are required and must be unique.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    needed = {\"Filename\", \"Clinical_Notes\"}\n",
    "    missing = needed - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns in CSV: {sorted(missing)}\")\n",
    "\n",
    "    # Keep only the columns we need for this task\n",
    "    df = df[[\"Filename\", \"Clinical_Notes\"]].copy()\n",
    "\n",
    "    # Basic sanity checks\n",
    "    if df[\"Filename\"].isna().any():\n",
    "        bad = df[df[\"Filename\"].isna()].index.tolist()\n",
    "        raise ValueError(f\"Found rows with missing Filename at indices: {bad[:10]}\")\n",
    "\n",
    "    # Filenames should be unique (one image per patient)\n",
    "    if df[\"Filename\"].duplicated().any():\n",
    "        dups = df[df[\"Filename\"].duplicated(keep=False)][\"Filename\"].tolist()\n",
    "        raise ValueError(f\"Duplicate Filenames detected (first 10): {dups[:10]}\")\n",
    "\n",
    "    # Normalize Clinical_Notes to string; keep NaNs as empty strings\n",
    "    df[\"Clinical_Notes\"] = df[\"Clinical_Notes\"].astype(str)\n",
    "    df.loc[df[\"Clinical_Notes\"].isin([\"nan\", \"NaN\", \"None\"]), \"Clinical_Notes\"] = \"\"\n",
    "    return df\n",
    "\n",
    "def _write_notes_files(df: pd.DataFrame, out_dir: Path, overwrite: bool = True) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Create <stem>.txt for each Filename, writing the verbatim Clinical_Notes.\n",
    "    Returns (num_written, num_skipped).\n",
    "    \"\"\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    written = 0\n",
    "    skipped = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        stem = Path(str(row[\"Filename\"])).stem\n",
    "        out_path = out_dir / f\"{stem}.txt\"\n",
    "\n",
    "        if out_path.exists() and not overwrite:\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        # Write verbatim; add trailing newline\n",
    "        text = (row[\"Clinical_Notes\"] or \"\").rstrip(\"\\n\")\n",
    "        out_path.write_text(text + \"\\n\", encoding=\"utf-8\")\n",
    "        written += 1\n",
    "\n",
    "    return written, skipped\n",
    "    \n",
    "# Create the reports_default directory and write one .txt per image stem with Clinical_Notes verbatim\n",
    "df_meta = _read_metadata(SOURCE_CSV)\n",
    "n = len(df_meta)\n",
    "written, skipped = _write_notes_files(df_meta, OUT_DIR, overwrite=OVERWRITE)\n",
    "\n",
    "print(f\"Output directory: {OUT_DIR}\")\n",
    "print(f\"Rows in CSV: {n}\")\n",
    "print(f\"Files written: {written}\")\n",
    "print(f\"Files skipped (exist & OVERWRITE=False): {skipped}\")\n",
    "\n",
    "# Quick verification: ensure a .txt exists for every Filename in CSV\n",
    "missing = []\n",
    "for fn in df_meta[\"Filename\"]:\n",
    "    p = OUT_DIR / f\"{Path(fn).stem}.txt\"\n",
    "    if not p.exists():\n",
    "        missing.append(p.name)\n",
    "\n",
    "if missing:\n",
    "    print(\"❌ Missing files (first 10 shown):\", missing[:10])\n",
    "else:\n",
    "    print(\"✅ One .txt per Filename present in reports_default.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2268b1-f72d-4aae-9bf4-0db487abe414",
   "metadata": {},
   "source": [
    "## END OF CODE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_class_py39)",
   "language": "python",
   "name": "pytorch_class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
