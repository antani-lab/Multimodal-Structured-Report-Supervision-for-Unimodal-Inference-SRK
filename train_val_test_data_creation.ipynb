{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12a25d57-6f01-4074-98fe-3fa0e2322c15",
   "metadata": {},
   "source": [
    "### Jupyter-ready, fully reproducible pipeline that:\n",
    "\n",
    "1. reads shen_demo.csv (Shenzhen metadata file) from the given path,\n",
    "\n",
    "2. maps classes (Normal→0, TB→1),\n",
    "\n",
    "3. verifies the class counts (expected: Normal=326, TB=336),\n",
    "\n",
    "4. makes a stratified, deterministic 70/20/10 split per class (exact counts),\n",
    "\n",
    "5. writes label_train.csv, label_valid.csv, label_test.csv (two columns, no header),\n",
    "\n",
    "6. and validates no leakage plus prints per-split class counts.\n",
    "\n",
    "The split is stratified per class with exact counts (using rounding for train/valid, remainder to test) for determinism and balance.\n",
    "\n",
    "Output files are exactly two columns, no header: Filename,Label where Label ∈ {0 (normal), 1 (tuberculosis)}.\n",
    "\n",
    "All checks are assertions; if anything is off (e.g., duplicates in input), the cell will raise with a clear message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a57d2b-7260-4498-8e41-f985d631884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------- Config ----------------\n",
    "SOURCE_CSV = Path(\"/shen_demo.csv\")\n",
    "OUT_DIR    = Path(\"/dataset\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRAIN_CSV = OUT_DIR / \"label_train.csv\"\n",
    "VALID_CSV = OUT_DIR / \"label_valid.csv\"\n",
    "TEST_CSV  = OUT_DIR / \"label_test.csv\"\n",
    "\n",
    "SEED = 2025  # deterministic\n",
    "\n",
    "CLASS_MAP: Dict[str, int] = {\n",
    "    \"normal\": 0,\n",
    "    \"tb\": 1,\n",
    "}\n",
    "\n",
    "EXPECTED_NORMAL = 326\n",
    "EXPECTED_TB = 336\n",
    "\n",
    "# --------------- Helpers ---------------\n",
    "def _load_and_map(source_csv: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load shen_demo.csv, keep at least [Filename, Class], map Class→Label (0/1).\"\"\"\n",
    "    df = pd.read_csv(source_csv)\n",
    "    # sanity\n",
    "    if \"Filename\" not in df.columns or \"Class\" not in df.columns:\n",
    "        raise ValueError(\"Input CSV must contain columns: 'Filename' and 'Class'.\")\n",
    "\n",
    "    # normalize class and map\n",
    "    cls_norm = df[\"Class\"].astype(str).str.strip().str.lower()\n",
    "    if not cls_norm.isin(CLASS_MAP.keys()).all():\n",
    "        bad = sorted(set(cls_norm.tolist()) - set(CLASS_MAP.keys()))\n",
    "        raise ValueError(f\"Found unknown class tokens: {bad}. Expected one of {list(CLASS_MAP)}\")\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"Label\"] = cls_norm.map(CLASS_MAP).astype(int)\n",
    "\n",
    "    # filename sanity\n",
    "    if df[\"Filename\"].isna().any():\n",
    "        raise ValueError(\"Found missing Filename values.\")\n",
    "    if df[\"Filename\"].duplicated().any():\n",
    "        dups = df[df[\"Filename\"].duplicated()][\"Filename\"].tolist()[:10]\n",
    "        raise ValueError(f\"Found duplicate Filenames (first 10): {dups}\")\n",
    "\n",
    "    return df[[\"Filename\", \"Label\"]]\n",
    "\n",
    "def _compute_target_counts(n: int, ratios: Tuple[float, float, float]) -> Tuple[int, int, int]:\n",
    "    \"\"\"Exact counts per class using round for train/valid, remainder to test.\"\"\"\n",
    "    r_train, r_valid, r_test = ratios\n",
    "    if abs(r_train + r_valid + r_test - 1.0) > 1e-8:\n",
    "        raise ValueError(\"Ratios must sum to 1.0\")\n",
    "    n_train = int(round(r_train * n))\n",
    "    n_valid = int(round(r_valid * n))\n",
    "    n_test = n - n_train - n_valid  # remainder\n",
    "    # Correct any rounding drift by nudging toward the largest remainder bucket if needed\n",
    "    if n_train < 0 or n_valid < 0 or n_test < 0:\n",
    "        raise ValueError(f\"Negative split sizes computed: {(n_train, n_valid, n_test)} for n={n}\")\n",
    "    return n_train, n_valid, n_test\n",
    "\n",
    "def _stratified_split_exact(df: pd.DataFrame, ratios=(0.7, 0.2, 0.1)) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Exact 70/20/10 per-class split (deterministic):\n",
    "      - shuffle each class deterministically\n",
    "      - slice exact counts per class\n",
    "    \"\"\"\n",
    "    train_parts = []\n",
    "    valid_parts = []\n",
    "    test_parts = []\n",
    "\n",
    "    for label, grp in df.groupby(\"Label\", sort=True):\n",
    "        grp_shuf = grp.sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
    "        n = len(grp_shuf)\n",
    "        n_train, n_valid, n_test = _compute_target_counts(n, ratios)\n",
    "\n",
    "        train_parts.append(grp_shuf.iloc[:n_train])\n",
    "        valid_parts.append(grp_shuf.iloc[n_train:n_train + n_valid])\n",
    "        test_parts.append(grp_shuf.iloc[n_train + n_valid:n_train + n_valid + n_test])\n",
    "\n",
    "    train_df = pd.concat(train_parts, axis=0).sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
    "    valid_df = pd.concat(valid_parts, axis=0).sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
    "    test_df = pd.concat(test_parts,  axis=0).sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "    # leakage checks\n",
    "    s_tr = set(train_df[\"Filename\"])\n",
    "    s_va = set(valid_df[\"Filename\"])\n",
    "    s_te = set(test_df[\"Filename\"])\n",
    "\n",
    "    assert s_tr.isdisjoint(s_va), \"Leakage: train ∩ valid is non-empty\"\n",
    "    assert s_tr.isdisjoint(s_te), \"Leakage: train ∩ test is non-empty\"\n",
    "    assert s_va.isdisjoint(s_te), \"Leakage: valid ∩ test is non-empty\"\n",
    "\n",
    "    # coverage check\n",
    "    all_src = set(df[\"Filename\"])\n",
    "    all_out = s_tr | s_va | s_te\n",
    "    assert all_src == all_out, \"Mismatch: union(train,valid,test) != all input Filenames\"\n",
    "\n",
    "    return train_df, valid_df, test_df\n",
    "\n",
    "def _save_label_csv(df: pd.DataFrame, path: Path) -> None:\n",
    "    \"\"\"Save as two columns [Filename, Label], no header, no index.\"\"\"\n",
    "    df[[\"Filename\", \"Label\"]].to_csv(path, index=False, header=False)\n",
    "\n",
    "def _print_counts_from_csv(path: Path) -> None:\n",
    "    df = pd.read_csv(path, header=None, names=[\"Filename\", \"Label\"])\n",
    "    counts = df[\"Label\"].value_counts().sort_index()\n",
    "    n0 = int(counts.get(0, 0))\n",
    "    n1 = int(counts.get(1, 0))\n",
    "    print(f\"{path.name}: total={len(df)} | normal(0)={n0} | tuberculosis(1)={n1}\")\n",
    "\n",
    "# run\n",
    "\n",
    "# 1) Load & map\n",
    "df_all = _load_and_map(SOURCE_CSV)\n",
    "\n",
    "# 2) Verify class counts (and show actuals)\n",
    "n_total = len(df_all)\n",
    "n_normal = int((df_all[\"Label\"] == 0).sum())\n",
    "n_tb = int((df_all[\"Label\"] == 1).sum())\n",
    "print(f\"Total={n_total} | Normal={n_normal} | TB={n_tb}\")\n",
    "\n",
    "# Check against the expected numbers you quoted\n",
    "if n_normal == EXPECTED_NORMAL and n_tb == EXPECTED_TB:\n",
    "    print(\"✅ Class counts match expected: Normal=326, TB=336.\")\n",
    "else:\n",
    "    print(f\"⚠️ Class counts differ from expected (Normal={EXPECTED_NORMAL}, TB={EXPECTED_TB}). \"\n",
    "          \"Proceeding with computed counts above.\")\n",
    "\n",
    "# 3) Stratified exact split (70/20/10 per class)\n",
    "train_df, valid_df, test_df = _stratified_split_exact(df_all, ratios=(0.7, 0.2, 0.1))\n",
    "\n",
    "# 4) Save CSVs (no header)\n",
    "_save_label_csv(train_df, TRAIN_CSV)\n",
    "_save_label_csv(valid_df, VALID_CSV)\n",
    "_save_label_csv(test_df,  TEST_CSV)\n",
    "\n",
    "print(f\"Saved:\\n- {TRAIN_CSV}\\n- {VALID_CSV}\\n- {TEST_CSV}\")\n",
    "\n",
    "# 5) Final verification: read back and print per-split class counts\n",
    "_print_counts_from_csv(TRAIN_CSV)\n",
    "_print_counts_from_csv(VALID_CSV)\n",
    "_print_counts_from_csv(TEST_CSV)\n",
    "\n",
    "# 6) Extra leakage check from files (defensive)\n",
    "df_tr = pd.read_csv(TRAIN_CSV, header=None, names=[\"Filename\",\"Label\"])\n",
    "df_va = pd.read_csv(VALID_CSV, header=None, names=[\"Filename\",\"Label\"])\n",
    "df_te = pd.read_csv(TEST_CSV,  header=None, names=[\"Filename\",\"Label\"])\n",
    "\n",
    "st, sv, se = set(df_tr[\"Filename\"]), set(df_va[\"Filename\"]), set(df_te[\"Filename\"])\n",
    "assert st.isdisjoint(sv), \"Leakage after save: train ∩ valid non-empty\"\n",
    "assert st.isdisjoint(se), \"Leakage after save: train ∩ test non-empty\"\n",
    "assert sv.isdisjoint(se), \"Leakage after save: valid ∩ test non-empty\"\n",
    "print(\"✅ No filename leakage across train/valid/test.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa0d0fb-7678-4821-996b-44f344849232",
   "metadata": {},
   "source": [
    "### Expected output\n",
    "\n",
    "Total=662 | Normal=326 | TB=336\n",
    "\n",
    "✅ Class counts match expected: Normal=326, TB=336.\n",
    "\n",
    "Saved:\n",
    "- /dataset/label_train.csv\n",
    "\n",
    "- /dataset/label_valid.csv\n",
    "\n",
    "- /dataset/label_test.csv\n",
    "\n",
    "label_train.csv: total=463 | normal(0)=228 | tuberculosis(1)=235\n",
    "\n",
    "label_valid.csv: total=132 | normal(0)=65 | tuberculosis(1)=67\n",
    "\n",
    "label_test.csv: total=67 | normal(0)=33 | tuberculosis(1)=34\n",
    "\n",
    "✅ No filename leakage across train/valid/test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba27e5fa-e7f4-4cbb-a3a9-b6a773a35d4e",
   "metadata": {},
   "source": [
    "## END OF CODE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_class_py39)",
   "language": "python",
   "name": "pytorch_class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
